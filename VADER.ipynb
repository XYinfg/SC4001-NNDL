{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb51affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2a4df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "      <td>know listenin bad habit earlier started freaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>layin n bed headache ughhhhwaitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends soon</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>we want to trade with someone who has houston...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>happy mothers day  all my love</td>\n",
       "      <td>happy mother day love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>happy mothers day to all the mommies out there...</td>\n",
       "      <td>happy mother day mommy woman man long youre mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>wassup beautiful follow me  peep out my new h...</td>\n",
       "      <td>wassup beautiful follow peep new hit single de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>bullet train from tokyo    the gf and i have ...</td>\n",
       "      <td>bullet train tokyo gf visiting japan since thu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \\\n",
       "0       i know  i was listenin to bad habit earlier a...   \n",
       "1      layin n bed with a headache  ughhhhwaitin on y...   \n",
       "2                          funeral ceremonygloomy friday   \n",
       "3                    wants to hang out with friends soon   \n",
       "4       we want to trade with someone who has houston...   \n",
       "...                                                  ...   \n",
       "39995                                                      \n",
       "39996                     happy mothers day  all my love   \n",
       "39997  happy mothers day to all the mommies out there...   \n",
       "39998   wassup beautiful follow me  peep out my new h...   \n",
       "39999   bullet train from tokyo    the gf and i have ...   \n",
       "\n",
       "                                       processed_content  \n",
       "0      know listenin bad habit earlier started freaki...  \n",
       "1                 layin n bed headache ughhhhwaitin call  \n",
       "2                          funeral ceremonygloomy friday  \n",
       "3                                  want hang friend soon  \n",
       "4                  want trade someone houston ticket one  \n",
       "...                                                  ...  \n",
       "39995                                                     \n",
       "39996                              happy mother day love  \n",
       "39997  happy mother day mommy woman man long youre mo...  \n",
       "39998  wassup beautiful follow peep new hit single de...  \n",
       "39999  bullet train tokyo gf visiting japan since thu...  \n",
       "\n",
       "[40000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('text_emotion.csv')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs, mentions, hashtags, and special characters\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the content column\n",
    "df['content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "# Stopword removal and lemmatization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords_and_lemmatize(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply stopword removal and lemmatization to the content column\n",
    "df['processed_content'] = df['content'].apply(remove_stopwords_and_lemmatize)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444778a",
   "metadata": {},
   "source": [
    "# VADER with Linear Regression\n",
    "\n",
    "\n",
    "The VADER (Valence Aware Dictionary and sEntiment Reasoner) score is a sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It provides a compound score that aggregates the cumulative sentiment of a text, ranging from -1 (most extreme negative) to +1 (most extreme positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa69cc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>vader_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "      <td>know listenin bad habit earlier started freaki...</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>layin n bed headache ughhhhwaitin call</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>-0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends soon</td>\n",
       "      <td>want hang friend soon</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>we want to trade with someone who has houston...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>-0.3919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>happy mothers day  all my love</td>\n",
       "      <td>happy mother day love</td>\n",
       "      <td>0.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>happy mothers day to all the mommies out there...</td>\n",
       "      <td>happy mother day mommy woman man long youre mo...</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>wassup beautiful follow me  peep out my new h...</td>\n",
       "      <td>wassup beautiful follow peep new hit single de...</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>bullet train from tokyo    the gf and i have ...</td>\n",
       "      <td>bullet train tokyo gf visiting japan since thu...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \\\n",
       "0       i know  i was listenin to bad habit earlier a...   \n",
       "1      layin n bed with a headache  ughhhhwaitin on y...   \n",
       "2                          funeral ceremonygloomy friday   \n",
       "3                    wants to hang out with friends soon   \n",
       "4       we want to trade with someone who has houston...   \n",
       "...                                                  ...   \n",
       "39995                                                      \n",
       "39996                     happy mothers day  all my love   \n",
       "39997  happy mothers day to all the mommies out there...   \n",
       "39998   wassup beautiful follow me  peep out my new h...   \n",
       "39999   bullet train from tokyo    the gf and i have ...   \n",
       "\n",
       "                                       processed_content  vader_score  \n",
       "0      know listenin bad habit earlier started freaki...      -0.5423  \n",
       "1                 layin n bed headache ughhhhwaitin call       0.0000  \n",
       "2                          funeral ceremonygloomy friday      -0.3612  \n",
       "3                                  want hang friend soon       0.4767  \n",
       "4                  want trade someone houston ticket one      -0.3919  \n",
       "...                                                  ...          ...  \n",
       "39995                                                          0.0000  \n",
       "39996                              happy mother day love       0.8360  \n",
       "39997  happy mother day mommy woman man long youre mo...       0.5719  \n",
       "39998  wassup beautiful follow peep new hit single de...       0.5994  \n",
       "39999  bullet train tokyo gf visiting japan since thu...       0.0000  \n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Sentiment Intensity Scores using VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['vader_score'] = df['content'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Combine TF-IDF features with VADER scores\n",
    "features = np.hstack((tfidf_features.toarray(), df['vader_score'].values.reshape(-1, 1)))\n",
    "\n",
    "# Now 'features' contains the TF-IDF vectors with VADER sentiment scores appended to each vector\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637f2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert categorical to numerical for regression\n",
    "emotion_intensity_map = {\n",
    "    'empty': 0,\n",
    "    'boredom': 1,\n",
    "    'neutral': 2,\n",
    "    'relief': 3,\n",
    "    'surprise': 4,\n",
    "    'fun': 5,\n",
    "    'worry': 6,\n",
    "    'sadness': 7,\n",
    "    'happiness': 8,\n",
    "    'love': 9,\n",
    "    'enthusiasm': 10,\n",
    "    'anger': 11,\n",
    "    'hate': 12\n",
    "}\n",
    "\n",
    "def convert_categorical_to_numerical(sentiment):\n",
    "    return emotion_intensity_map.get(sentiment, -1)\n",
    "\n",
    "df['sentiment_intensity'] = df['sentiment'].apply(convert_categorical_to_numerical)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['sentiment_intensity'], test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1174ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837465ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.283080635248068\n",
      "R^2 Score: 0.08335281671616335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f748713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 7.2831\n",
      "Pearson Correlation Coefficient: 0.3030\n",
      "Concordance Correlation Coefficient (CCC): 0.2068\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to calculate Concordance Correlation Coefficient\n",
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    pearson_corr = pearsonr(y_true, y_pred)[0]\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    sd_true = np.sqrt(var_true)\n",
    "    sd_pred = np.sqrt(var_pred)\n",
    "    numerator = 2 * pearson_corr * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred) ** 2\n",
    "    return numerator / denominator\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "true_labels = y_test\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(true_labels, predictions)\n",
    "pearson_corr, _ = pearsonr(true_labels, predictions)\n",
    "ccc = concordance_correlation_coefficient(true_labels, predictions)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Pearson Correlation Coefficient: {pearson_corr:.4f}')\n",
    "print(f'Concordance Correlation Coefficient (CCC): {ccc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9befcb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion Intensity: 6.736018505782546\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "new_data = [\"I'm so happy to see you!\"]\n",
    "new_data_processed = tfidf_vectorizer.transform(new_data)\n",
    "new_data_vader_score = analyzer.polarity_scores(new_data[0])['compound']\n",
    "new_data_features = np.hstack((new_data_processed.toarray(), [[new_data_vader_score]]))\n",
    "\n",
    "predicted_intensity = model.predict(new_data_features)\n",
    "print(f'Predicted Emotion Intensity: {predicted_intensity[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12065a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
